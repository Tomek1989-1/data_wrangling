{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "857747a4",
   "metadata": {},
   "source": [
    "I started my wrangling efforts by creating three separate dataframes. The first one called 'dataframe_twitter' was created from a .csv file using 'pandas' library. The second one called 'dataframe_image' was created from a .tsv file downloaded from the web using 'requests' and 'pandas' libraries. The third one called 'dataframe_api' was created from json file using 'for' loop and 'pandas' library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09546093",
   "metadata": {},
   "source": [
    "My second step was to assess the dataframes that were created. I used both visual and programmatic assessment using .head(), .info() and .describe() methods. Then I listed 9 quality and 3 tidiness issues that I found and want to address in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b28fa29",
   "metadata": {},
   "source": [
    "I started cleaning data by copying previously created dataframes. In my first cleaning effort I removed all retweets from the dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635e8896",
   "metadata": {},
   "source": [
    "In my second cleaning effort I addressed 5 cleaning issues related to incorrect datatypes and wrong values in particular cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff73b83",
   "metadata": {},
   "source": [
    "My third cleaning effort was to remove tweets with rating_numerator value large or small enough to treat them as outliers. I have removed all the rows with rating_numerator value smaller than Q1-1.5\\*IQR and larger than Q3+1.5\\*IQR where Q1 and Q3 are first and third quartiles respectively and IQR equals Q3-Q1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b24c4e8",
   "metadata": {},
   "source": [
    "My fourth cleaning effort was to clean up rows with rating_denominator not equals to 10. With rating_denominator not equals 10 the rating_numerator was impossible to interpret. I updated both rating_numerator and rating_denominator for these lines so that rating_denominator equals 10 and I kept the same proportion between rating_numerator and rating_denominator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccafe3e",
   "metadata": {},
   "source": [
    "My fifth cleaning effort was to address quality issue #9. In 'name' column missing values were represented by 'None' string and pandas library considered these entries as valid values. I decided to replace all 'None' entries with NaN (missing) values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af10d5b2",
   "metadata": {},
   "source": [
    "My sixth cleaning effort was focused on creating one column that would include the information about dog's stage. I started with replacing all the 'None' strings with empty string and then combined four columns related to the dog's stage ('doggo', 'floofer', 'pupper', 'puppo') into one column called 'stage'. For rows with no stage information I replaced empty strings with NaN values. There were also some cells with mixed stages like 'doggopuppo' because some pictures included more than one dog. I decided to remove mixed stage values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6266c91b",
   "metadata": {},
   "source": [
    "My seventh cleaning effort was to create column with information about dog's breed. If 'p1_dog' value was 'True' dog's breed could be found in 'p1' column. If 'p1_dog' value was 'False' I decided to search for this information in columns 'p2' and 'p3' respectively using the same criteria as for 'p1'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878c6871",
   "metadata": {},
   "source": [
    "My eighth cleaning effort was to create a single master dataframe (df_master) with all the columns ('tweet_id', 'rating_numerator', 'retweet_count', 'favorite_count', 'stage', 'breed') required for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75db8621",
   "metadata": {},
   "source": [
    "In the last step of data wrangling effort I created a .csv file with master dataframe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
